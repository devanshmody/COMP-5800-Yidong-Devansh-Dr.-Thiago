{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataVisualization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHOaMqWV457x"
      },
      "source": [
        "import nltk\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from wordcloud import WordCloud\n",
        "import plotly.express as px\n",
        "import plotly.figure_factory as ff"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Df0NGVaT1aYU"
      },
      "source": [
        "#function to plot words \n",
        "def wc(data,bgcolor,title):\n",
        "    plt.figure(figsize = (13,10))\n",
        "    wc = WordCloud(background_color = bgcolor, max_words = 1000,  max_font_size = 50)\n",
        "    wc.generate(' '.join(data))\n",
        "    plt.title(title , fontsize = 20)\n",
        "    plt.imshow(wc)\n",
        "    plt.axis('off')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az-wkFp41Jj0"
      },
      "source": [
        "#function to plot frequency of words in a bar style plot\n",
        "def show_wfreq_plot(df):    \n",
        "    freq_dist = nltk.FreqDist(df)    \n",
        "    ls_freq = [(word, frequency) for word, frequency in freq_dist.most_common(20)]\n",
        "    twdf = pd.DataFrame(ls_freq, columns=[\"Word\", \"Frequency\"])\n",
        "    tfig = px.bar(twdf, x=\"Word\", y=\"Frequency\", title=\"Top 20 most frequent words\")\n",
        "    tfig.show() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xnSZYNpoZbKf"
      },
      "source": [
        "#function to plot some statistics about the data\n",
        "def plot_some_stats(df,word_counts,missing_words,vocab_to_int):\n",
        "  print(\"\\nLength of the final data: {}\".format(len(df)))\n",
        "  print(\"\\nSome information regarding data\\n {}\".format(df.info))\n",
        "  print(\"\\nDescription of data\\n {}\".format(df.describe()))\n",
        "  print(\"\\nTotal count of labels\\n {}\".format(df[\"Label\"].value_counts()))\n",
        "  print(\"\\nSamples which are not Hate Speech\\n {}\".format(df.loc[df.Label == str(0), ['Content']].sample(5).values))\n",
        "  print(\"\\nSamples which are Hate Speech\\n {}\".format(df.loc[df.Label == str(1), ['Content']].sample(5).values))\n",
        "  #find ratio of missing words\n",
        "  missing_ratio = round(len(missing_words)/len(word_counts),4)*100\n",
        "  print(\"\\nNumber of words missing from word_embeddings:\", len(missing_words))\n",
        "  print(\"\\nPercent of words that are missing from our vocabulary: {}%\".format(missing_ratio))\n",
        "  print(\"\\nvoc_to_int_ index position of tokens UNK is {}, PAD is {}, EOS is {} and GO is {} \".format(vocab_to_int['<UNK>'],vocab_to_int['<PAD>'],vocab_to_int['<EOS>'],vocab_to_int['<GO>']))\n",
        "  print(\"\\n\",df['Label'].value_counts().plot(kind = 'pie'))\n",
        "  print(\"\\n\",wc(word_counts,\"black\",\"Most Frequent Words\"))\n",
        "  print(\"\\n\",show_wfreq_plot(word_counts))\n",
        "  print(\"\\n\",wc(missing_words,\"black\",\"Missing Words\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nET3ULWjHErd"
      },
      "source": [
        "#function to plot the length of training, validation and testing\n",
        "def plot_tr_tval_tt_len(xtr,xval,xtt):\n",
        "  names = ['Training','Validation','Testing']\n",
        "  values = [len(xtr),len(xval),len(xtt)]\n",
        "  plt.figure(figsize=(10,5))\n",
        "  plt.subplot(131)\n",
        "  plt.bar(names,values,color=['darkorange','coral','coral'],edgecolor='darkblue')\n",
        "  plt.suptitle('Categorical Plotting')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psPF7N0DHwdf"
      },
      "source": [
        "#function to plot loss and accuracy curves on training and validation set\n",
        "def plotgraph(history):\n",
        "  plt.figure(figsize=[8,6])\n",
        "  plt.plot(history.history['loss'],'firebrick',linewidth=3.0)\n",
        "  plt.plot(history.history['accuracy'],'turquoise',linewidth=3.0)\n",
        "  plt.plot(history.history['val_loss'],'midnightblue',linewidth=3.0)\n",
        "  plt.legend(['Training loss','Training Accuracy','Validation loss'],fontsize=18)\n",
        "  plt.xlabel('Epochs',fontsize=16)\n",
        "  plt.ylabel('Loss and Accuracy',fontsize=16)\n",
        "  plt.title('Loss Curves and Accuracy Curves for text summarization',fontsize=16)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}