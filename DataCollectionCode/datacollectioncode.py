# -*- coding: utf-8 -*-
"""DataCollectionCode.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1us4TQSS7bGvHMxH1h8BocHnIGhOs8XQ2
"""

pip install datasets

import pandas as pd
from google.colab import drive
import numpy as np
import os
import xml.etree.ElementTree as Xet
import pandas as pd
import datasets
drive.mount('/content/drive')

"""</b>ALL DATA COLLECTION CODES ARE WRITTEN BELOW </b>"""

def DC():

  #getting datafrom path "/content/drive/MyDrive/compfinalproject/jf4pzyvnpj-1"
  #read the csv files from the respective paths
  df = pd.read_csv("/content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/Dataset/devansh/jf4pzyvnpj-1/aggression_parsed_dataset.csv")
  df1 = pd.read_csv("/content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/Dataset/devansh/jf4pzyvnpj-1/attack_parsed_dataset.csv")
  df2 = pd.read_csv("/content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/Dataset/devansh/jf4pzyvnpj-1/kaggle_parsed_dataset.csv")
  df3 = pd.read_csv("/content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/Dataset/devansh/jf4pzyvnpj-1/toxicity_parsed_dataset.csv")
  df4 = pd.read_csv("/content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/Dataset/devansh/jf4pzyvnpj-1/twitter_parsed_dataset.csv")
  df5 = pd.read_csv("/content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/Dataset/devansh/jf4pzyvnpj-1/twitter_racism_parsed_dataset.csv")
  df6 = pd.read_csv("/content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/Dataset/devansh/jf4pzyvnpj-1/twitter_sexism_parsed_dataset.csv")
  df7 = pd.read_csv("/content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/Dataset/devansh/jf4pzyvnpj-1/youtube_parsed_dataset.csv")

  #combine all the data frames into one single data frame
  final_df = pd.concat([df,df1,df2,df3,df4,df5,df6,df7], axis=0, join='outer',ignore_index=False, verify_integrity=False, sort=False, copy=True)

  #reset the index positions of the dataframe
  final_df.reset_index(inplace=True)
  
  #rename the labels with their actual meaning 1=HateSpeech and 0=NoHate
  final_df['oh_label'] = ["HateSpeech" if val==1 else val for val in final_df['oh_label']]
  final_df['oh_label'] = ["NoHate" if val==0 else val for val in final_df['oh_label']]

  #rename column
  final_df.rename(columns={"oh_label": "Label","Text":"Content"},inplace=True)

  #remove nan values from the dataframe
  final_df = final_df[final_df['Label'].notna()]

  print("\nTotal Length DC",len(final_df))

  #keep selected columns only
  final_df = final_df[["Content","Label"]]

  print(final_df.head(2))

  print(final_df["Label"].unique())

  return final_df

def DC1():

  #download dataset from the hugging face website
  dc1 = datasets.load_dataset("5roop/FRENK-hate-hr","binary") 

  #create empty dataframes
  df = pd.DataFrame(columns = ["text", "label"]) 
  df1 = pd.DataFrame(columns = ["text", "label"]) 
  df2 = pd.DataFrame(columns = ["text", "label"]) 

  #copy data to the dataframes
  df["text"] = dc1["train"]["text"]
  df["label"] = dc1["train"]["label"]

  df1["text"] = dc1["test"]["text"]
  df1["label"] = dc1["test"]["label"]

  df2["text"] = dc1["validation"]["text"]
  df2["label"] = dc1["validation"]["label"]

  #combine all the data frames into one single data frame
  final_df = pd.concat([df,df1,df2], axis=0, join='outer',ignore_index=False, verify_integrity=False, sort=False, copy=True)

  #reset the index positions of the dataframe
  final_df.reset_index(inplace=True)
  
  #rename the labels with their actual meaning 1=HateSpeech and 0=NoHate
  final_df['label'] = ["HateSpeech" if val==1 else val for val in final_df['label']]
  final_df['label'] = ["NoHate" if val==0 else val for val in final_df['label']]

  #remove nan values from the dataframe
  final_df = final_df[final_df['label'].notna()]

  #rename column
  final_df.rename(columns={"label": "Label","text":"Content"},inplace=True)

  print("\nTotal Length DC1",len(final_df))

  #keep selected columns only
  final_df = final_df[["Content","Label"]]

  print(final_df.head(2))

  print(final_df["Label"].unique())

  return final_df

def DC2():

  #download dataset from hugging face
  data = datasets.load_dataset('hate_speech18')

  #create empty dataframe
  final_df = pd.DataFrame(columns=["text","label"])
  final_df["text"] = data["train"]["text"]
  final_df["label"] = data["train"]["label"]

  #rename the labels with their actual meaning 1=HateSpeech and 0=NoHate
  final_df['label'] = ["HateSpeech" if val==1 else val for val in final_df['label']]

  #0=no hate speech
  #1=hate speech
  #2=original idk/skip mapped no hate speech
  #3=original relation mapped to no hate speech
  
  final_df['label'] = ["NoHate" if val==0 else val for val in final_df['label']]
  final_df['label'] = ["NoHate" if val==2 else val for val in final_df['label']]
  final_df['label'] = ["NoHate" if val==3 else val for val in final_df['label']]

  #remove nan values from the dataframe
  final_df = final_df[final_df['label'].notna()]

  #rename column
  final_df.rename(columns={"label": "Label","text":"Content"},inplace=True)

  print("\nTotal Length DC2",len(final_df))

  #keep selected columns only
  final_df = final_df[["Content","Label"]]

  print(final_df.head(2))

  print(final_df["Label"].unique())

  return final_df

def DC3():

  #read data from the path
  df = pd.read_csv("/content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/Dataset/devansh/Twitter Sentiment Analysis/train.csv")
  df1 = pd.read_csv("/content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/Dataset/devansh/Twitter Sentiment Analysis/test.csv")

  #combine all the data frames into one single data frame
  final_df = pd.concat([df,df1], axis=0, join='outer',ignore_index=False, verify_integrity=False, sort=False, copy=True)

  #reset the index positions of the dataframe
  final_df.reset_index(inplace=True)
  
  #rename the labels with their actual meaning 1=HateSpeech and 0=NoHate
  final_df['label'] = ["HateSpeech" if val==1 else val for val in final_df['label']]
  final_df['label'] = ["NoHate" if val==0 else val for val in final_df['label']]

  #remove nan values from the dataframe
  final_df = final_df[final_df['label'].notna()]

  #rename column
  final_df.rename(columns={"label": "Label","tweet":"Content"},inplace=True)

  print("\nTotal Length DC3",len(final_df))

  #keep selected columns only
  final_df = final_df[["Content","Label"]]

  print(final_df.head(2))

  print(final_df["Label"].unique())

  return final_df

def DC4():

  #read data from the path
  df = pd.read_csv("/content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/Dataset/devansh/Malignant Comment Classification/train.csv")
  df1 = pd.read_csv("/content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/Dataset/devansh/Malignant Comment Classification/test.csv")

  #combine all the data frames into one single data frame
  final_df = pd.concat([df,df1], axis=0, join='outer',ignore_index=False, verify_integrity=False, sort=False, copy=True)

  #reset the index positions of the dataframe
  final_df.reset_index(inplace=True)
  
  #rename the labels with their actual meaning 1=HateSpeech and 0=NoHate
  final_df["malignant"] = ["HateSpeech" if val==1 else val for val in final_df['malignant']]
  final_df["malignant"] = ["NoHate" if val==0 else val for val in final_df['malignant']]

  #rename column
  final_df.rename(columns={"malignant":"Label","comment_text":"Content"},inplace=True)

  #keep selected columns only 
  final_df = final_df[["Content","Label"]]

  #remove nan values from the dataframe
  final_df = final_df[final_df['Label'].notna()]

  print("\nTotal Length DC4",len(final_df))

  print(final_df.head(2))

  print(final_df["Label"].unique())

  return final_df

def DC5():

  #read data from the path
  final_df = pd.read_csv("/content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/Dataset/devansh/Classified Tweets/classified_tweets.csv")
  
  #rename column
  final_df.rename(columns={"hate":"Label","text":"Content"},inplace=True)

  #rename the labels with their actual meaning 1=HateSpeech and 0=NoHate
  final_df["Label"] = ["HateSpeech" if val==1 else val for val in final_df['Label']]
  final_df["Label"] = ["NoHate" if val==0 else val for val in final_df['Label']]

  #keep selected columns only 
  final_df = final_df[["Content","Label"]]

  #drop unwanted rows
  final_df = final_df.drop(final_df[final_df.Label == 2].index)

  #remove nan values from the dataframe
  final_df = final_df[final_df['Label'].notna()]

  print("\nTotal Length DC5",len(final_df))

  print(final_df.head(2))

  print(final_df["Label"].unique())

  return final_df

def DC6():

  #read data from the path
  final_df = pd.read_csv("/content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/Dataset/devansh/Dynamically Generated Hate Speech Dataset/2020-12-31-DynamicallyGeneratedHateDataset-entries-v0.1.csv")
    
  #rename the labels with their actual meaning 1=HateSpeech and 0=NoHate
  final_df["label"] = ["HateSpeech" if val=="hate" else val for val in final_df['label']]
  final_df["label"] = ["NoHate" if val=="nothate" else val for val in final_df['label']]

  #remove nan values from the dataframe
  final_df = final_df[final_df['label'].notna()]

  #rename column
  final_df.rename(columns={"label": "Label","text":"Content"},inplace=True)

  print("\nTotal Length DC6",len(final_df))

  final_df = final_df[["Content","Label"]]

  print(final_df.head(2))

  print(final_df["Label"].unique())

  return final_df

def DC7():

  #read data from the path
  final_df = pd.read_csv("/content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/Dataset/devansh/Hate Speech and Offensive Language Dataset/labeled_data.csv")
  
  #rename column
  final_df.rename(columns={"class":"Label","tweet":"Content"},inplace=True)

  #rename the labels with their actual meaning 1=HateSpeech and 0=NoHate
  final_df["Label"] = ["HateSpeech" if val==0 else val for val in final_df['Label']]
  final_df["Label"] = ["NoHate" if val==1 else val for val in final_df['Label']]
  final_df["Label"] = ["NoHate" if val==2 else val for val in final_df['Label']]

  #keep selected columns only 
  final_df = final_df[["Content","Label"]]

  #remove nan values from the dataframe
  final_df = final_df[final_df['Label'].notna()]

  print("\nTotal Length DC7",len(final_df))

  print(final_df.head(2))

  print(final_df["Label"].unique())

  return final_df

def DC8():
  
  #read data from path 
  #the data is in xml files so extract text and assign label to the text 
  data = os.listdir("/content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/Dataset/devansh/chatcoderwebsitedata/BayzickBullyingData")
  df_xml = pd.DataFrame(columns=["text","label"])
  edf = pd.DataFrame(columns=["File Name","Is Cyberbullying Present?"])
  for folder in data:
    #print(folder)
    if folder=="Human Concensus":
      for i in range(0,11):
        df = pd.read_excel("/content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/Dataset/devansh/chatcoderwebsitedata/BayzickBullyingData/Human Concensus/Packet{}Consensus.xlsx".format(i+1))
        df.columns = df.iloc[1]
        df = df[2:]
        df = df[df.columns[:2]]
        edf = pd.concat([edf,df], ignore_index=True)
        edf.drop_duplicates(subset=['File Name'],ignore_index=True,inplace=True)
      edf = edf[["File Name","Is Cyberbullying Present?"]]
    else:
      xml_data = os.listdir("/content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/Dataset/devansh/chatcoderwebsitedata/BayzickBullyingData/{}".format(folder))
      cols = ["text","label"]
      rows = []
      for value in xml_data:
        # Parsing the XML file
        try:
          xmlparse = Xet.parse("/content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/Dataset/devansh/chatcoderwebsitedata/BayzickBullyingData/{}/{}".format(folder,value))
          root = xmlparse.getroot()
          for i in root:
            text_data = i.find("body").text
            rows.append({"text": text_data,
                     "label": value.split(".xml")[0]})
          df = pd.DataFrame(rows, columns=cols)
          df_xml = pd.concat([df_xml,df], ignore_index=True)
          df_xml.drop_duplicates(subset=['text'],ignore_index=True,inplace=True)
        except Exception as e:
          #print(e)
          pass

  #convert to string and remove empty spaces between strings
  df_xml["label"]=df_xml["label"].apply(str)
  df_xml["label"]=df_xml["label"].str.strip()

  edf["File Name"]=edf["File Name"].apply(str)
  edf["File Name"]=edf["File Name"].str.strip()

  listdf_xml=list(df_xml["label"])
  listedf=list(edf["File Name"])

  df_xml["label"]=listdf_xml
  edf["File Name"]=listedf
  
  #remane the columns
  edf.rename(columns={"File Name":"label"},inplace=True)

  #merge the columns
  df_xml=pd.merge(df_xml,edf,on="label",how="left")

  df_xml=df_xml[1:]

  #rename column names
  df_xml.rename(columns={"Is Cyberbullying Present?":"Label","text":"Content"},inplace=True)

  #rename the labels with their actual meaning 1=HateSpeech and 0=NoHate
  df_xml["Label"] = ["HateSpeech" if val=="Y" else val for val in df_xml['Label']]
  df_xml["Label"] = ["NoHate" if val=="N" else val for val in df_xml['Label']]

  #remove nan values from the dataframe
  df_xml = df_xml[df_xml['Label'].notna()]

  print("\nTotal Length DC8",len(df_xml))

  #keep selected columns only
  df_xml = df_xml[["Content","Label"]]

  print(df_xml.head(2))

  print(df_xml["Label"].unique())

  return df_xml

def DC9():
  
  #create empty lists
  labels = []
  texts = [] 
  #read the data from the path
  #traverse parent directory
  data_dir = os.listdir("/content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/Dataset/devansh/tweeteval")
  for i in data_dir:
    #traverse sub directory
    sub_dir = os.listdir("/content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/Dataset/devansh/tweeteval/{}".format(i))
    for j in sub_dir:
      if j.find("labels")!=-1:
        labels.extend(open("/content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/Dataset/devansh/tweeteval/{}/{}".format(i,j)).readlines())
      elif j.find("mapping")!=-1:
        pass
      else:
        texts.extend(open("/content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/Dataset/devansh/tweeteval/{}/{}".format(i,j)).readlines())  

  #create an empty dataframe 
  final_df = pd.DataFrame(columns=["Content","Label"])

  #copying values to the final dataframe
  final_df["Content"] = texts
  final_df["Label"] = labels

  #remove \n values
  final_df["Label"] = final_df["Label"].str.strip("\n")
  final_df["Content"] = final_df["Content"].str.strip("\n")

  #rename the labels with their actual meaning 1=HateSpeech and 0=NoHate
  final_df["Label"] = ["HateSpeech" if val=="1" else val for val in final_df['Label']]
  final_df["Label"] = ["NoHate" if val=="0" else val for val in final_df['Label']]

  #remove nan values from the dataframe
  final_df = final_df[final_df['Label'].notna()]

  print("\nTotal Length DC9",len(final_df))

  #keep selected columns only
  final_df = final_df[["Content","Label"]]

  print(final_df.head(2))

  print(final_df["Label"].unique())

  return final_df

def DC10():
  
  #read data from path
  df = pd.read_csv("/content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/Dataset/devansh/english_dataset/english_dataset.tsv",sep="\t")
  df1 = pd.read_csv("/content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/Dataset/devansh/english_dataset/hasoc2019_en_test-2919.tsv",sep="\t")

  #combine all the data frames into one single data frame
  final_df = pd.concat([df,df1], axis=0, join='outer',ignore_index=False, verify_integrity=False, sort=False, copy=True)

  #reset the index positions of the dataframe
  final_df.reset_index(inplace=True)
  
  #rename the labels with their actual meaning 1=HateSpeech and 0=NoHate
  final_df["task_1"] = ["HateSpeech" if val=="HATE" else val for val in final_df['task_1']]
  final_df["task_1"] = ["HateSpeech" if val=="HOF" else val for val in final_df['task_1']]
  final_df["task_1"] = ["NoHate" if val=="NOT" else val for val in final_df['task_1']]

  #rename column
  final_df.rename(columns={"task_1":"Label","text":"Content"},inplace=True)

  #keep selected columns only 
  final_df = final_df[["Content","Label"]]

  #remove nan values from the dataframe
  final_df = final_df[final_df['Label'].notna()]

  print("\nTotal Length DC10",len(final_df))

  print(final_df.head(2))

  print(final_df["Label"].unique())

  return final_df

#this function combines all the output dataframes from the data collection code written above
#the function genrates a csv file by combining output at a given path
def data_devansh():

  #call all the data collection functions written above
  dc  = DC()
  dc1 = DC1()
  dc2 = DC2()
  dc3 = DC3()
  dc4 = DC4()
  dc5 = DC5()
  dc6 = DC6()
  dc7 = DC7()
  dc8 = DC8()
  dc9 = DC9()
  dc10 = DC10()

  #combine all the data frames into one single data frame
  final_data = pd.concat([dc,dc1,dc2,dc3,dc4,dc5,dc6,dc7,dc8,dc9,dc10], axis=0, join='outer',ignore_index=False, verify_integrity=False, sort=False, copy=True)
  
  #reset index of the dataframe
  final_data.reset_index(inplace=True)

  #rename the labels with their actual meaning 1=HateSpeech and 0=NoHate
  final_data["Label"] = ["1" if val=="HateSpeech" else val for val in final_data['Label']]
  final_data["Label"] = ["0" if val=="NoHate" else val for val in final_data['Label']]

  print("\nTotal length of data collected by Devansh",len(final_data))

  print(final_data.head(2))

  print(final_data["Label"].unique())

  #write final data to the path
  final_data.to_csv("/content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/DataCollectionCode/data_devansh.csv",index=False)

if __name__:data_devansh()

#combine devansh and huang data collected code
def main():
  #read the data from the path 
  dev = pd.read_csv("/content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/DataCollectionCode/data_devansh.csv")
  hua = pd.read_csv("/content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/DataCollectionCode/data_huang.csv")

  #combine all the data frames into one single data frame
  final_data = pd.concat([dev,hua], axis=0, join='outer',ignore_index=False, verify_integrity=False, sort=False, copy=True)

  #keep selected columns only
  final_data = final_data[["Content","Label"]]

  print("Total length of the combined dataset Yidong Huang and Devansh Mody",len(final_data))

  print(final_data.head())

  print(final_data["Label"].unique())

  #write final data to the path
  final_data.to_csv("/content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/DataCollectionCode/data_huang_devansh.csv",index=False)

if __name__:main()

