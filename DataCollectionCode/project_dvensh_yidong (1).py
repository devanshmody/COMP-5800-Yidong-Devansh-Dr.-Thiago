# -*- coding: utf-8 -*-
"""Project_Dvensh_YiDong.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1P-J5nJoxjAo88sCv1-teBQtZ9xEcKRTY
"""

pip install chart-studio

import numpy as np 
import pandas as pd

from google.colab import drive
drive.mount('/content/drive')

#balanced_dataset.csv
#1 is hate speech 0 is not hate speech
#Bully dataset folder
def Bully_dataset():
  df_1 = pd.read_csv('/content/drive/MyDrive/HateSpeechDataSet/balanced_dataset.csv')

  df_1.rename(columns={'Comment':'Content','Insult':'Label'},inplace=True)

  df_temp = pd.read_csv("/content/drive/MyDrive/HateSpeechDataSet/clean_dataset.csv")
  print(df_temp.head())
  df_temp.rename(columns={'Comment':'Content','Insult':'Label'},inplace=True)
  print(df_temp.head())
  df_8 = df_temp
  return df_8,df_1

#Hath speech mlma folder
def HateSpeechmlma();
  df_temp = pd.read_csv('/content/drive/MyDrive/HateSpeechDataSet/en_dataset_with_stop_words.csv')
  pd.set_option('display.max_columns', None)

  df_temp1 = df_temp.iloc[0:5646,[1]]
  df_temp1['Label'] = 1
  df_temp1.rename(columns={'tweet':'Content'},inplace=True)
  df_2 = df_temp1
  print(df_temp1.head())
  return df_2

#detecting-insults-in-social-commentary folder
def detecting_insults_in_social_commentary():
  df_temp = pd.read_csv('/content/drive/MyDrive/HateSpeechDataSet/train.csv')
  print(df_temp.head())
  df_temp1 = df_temp.iloc[0:3900]['Comment']
  df_temp2 = df_temp.iloc[0:3900]['Insult']
  df_temp1 = df_temp1.to_frame(name='Comment')
  df_temp2 = df_temp2.to_frame(name='Insult')
  df_3 = df_temp1.join(df_temp2)
  df_3.rename(columns={'Comment':'Content','Insult':'Label'},inplace=True)
  print(df_3)
  return df_3

#Twitter hatespeech
def Twitter_hatespeech():
  df_temp = pd.read_csv('/content/drive/MyDrive/HateSpeechDataSet/train_E6oV3lV.csv')
  print(df_temp.head())

  df_temp1 = df_temp.iloc[0:31961]['tweet']
  df_temp2 = df_temp.iloc[0:31961]['label']
  df_temp1 = df_temp1.to_frame(name='tweet')
  df_temp2 = df_temp2.to_frame(name='label')
  df_4 = df_temp1.join(df_temp2)
  df_4.rename(columns={'tweet':'Content','label':'Label'},inplace=True)

  print(df_4.head())
  return df_4

#hatespeech_andOffensive_language

def Hate_speech_and_offensive_language():
  df_temp = pd.read_csv('/content/drive/MyDrive/HateSpeechDataSet/labeled_data_another.csv')
  print(df_temp)
  df_temp1 = df_temp.iloc[[1,24782],[6]]

  for i in range(24783):
    if df_temp.loc[i,'class'] != 2:
      df_temp.loc[i,'class'] = 1
    else:
      df_temp.loc[i,'class'] = 0

  pd.set_option('display.max_columns', None)

  df_temp2 = df_temp.iloc[[1,24782],[5]]

  df_5 = df_temp1.join(df_temp2)
  df_5.rename(columns={'tweet':'Content','class':'Label'},inplace=True)
  print(df_5.head())
  return df_5

#Hate speech offensive tweets by Davidson
def HatespeechOffensiveTweetwByDavidson():
  df_temp = pd.read_csv('/content/drive/MyDrive/HateSpeechDataSet/labeled_data.csv')
  print(df_temp.head())

  df_temp1 = df_temp.iloc[[1,24782],[6]]

  for i in range(24783):
    if df_temp.loc[i,'class'] != 2:
      df_temp.loc[i,'class'] = 1
    else:
      df_temp.loc[i,'class'] = 0

  pd.set_option('display.max_columns', None)

  df_temp2 = df_temp.iloc[[1,24782],[5]]

  df_6 = df_temp1.join(df_temp2)
  df_6.rename(columns={'tweet':'Content','class':'Label'},inplace=True)
  print(df_6.head())
  return df_6

#Hate_speech_dataset
def Hate_Speech_Dataset():
  df_temp = pd.read_csv('/content/drive/MyDrive/HateSpeechDataSet/hate_speech.csv')
  print(df_temp.head())
  df_temp1 = df_temp.iloc[[1,9924],[2]]
  df_temp2 = df_temp.iloc[[1,9924],[1]]

  df_temp1 = df_temp.iloc[0:31961]['post']
  df_temp2 = df_temp.iloc[0:31961]['label']
  df_temp1 = df_temp1.to_frame(name='post')
  df_temp2 = df_temp2.to_frame(name='label')

  df_7 = df_temp1.join(df_temp2)

  df_7.rename(columns={'post':'Content','label':'Label'},inplace=True)
  print(df_7.head())
  return df_7

df_temp = pd.read_csv("/content/drive/MyDrive/HateSpeechDataSet/clean_dataset.csv")
print(df_temp.head())
df_temp.rename(columns={'Comment':'Content','Insult':'Label'},inplace=True)
print(df_temp.head())
df_8 = df_temp

df_final_2 = pd.read_csv("/content/drive/MyDrive/HateSpeechDataSet/data_huang_devansh.csv")
df_final_1 = pd.read_csv("/content/data_huang.csv")
print((df_final_2.size))
df_final_3 = df_final_2.merge(df_final_1,on=['Content','Label'],left_index=True,right_index=True, how='outer')
print((df_final_3.size))
df_final_3.to_csv("data_huang.csv")

def Add_more_Data():
  df_temp_I = pd.read_csv('/content/drive/MyDrive/HateSpeechDataSet/impermium_verification_labels.csv')
  df_temp_test = pd.read_csv('/content/drive/MyDrive/HateSpeechDataSet/test_with_solutions.csv')
  df_huang = pd.read_csv('/content/drive/MyDrive/HateSpeechDataSet/data_huang.csv')
  print(df_huang.size)

  df_temp_I.rename(columns={'Comment':'Content','Insult':'Label'},inplace=True)
  df_temp1 = df_temp_I.iloc[0:2235]['Content']
  df_temp2 = df_temp_I.iloc[0:2235]['Label']
  df_temp1 = df_temp1.to_frame(name='Content')
  df_temp2 = df_temp2.to_frame(name='Label')
  df_3_1 = df_temp1.join(df_temp2)
  table = [df_3_1,df_huang]
  pd.concat(table)

  #54930
  df_temp_test.rename(columns={'Comment':'Content','Insult':'Label'},inplace=True)
  df_temp1 = df_temp_test.iloc[0:2647]['Content']
  df_temp2 = df_temp_test.iloc[0:2647]['Label']
  df_temp1 = df_temp1.to_frame(name='Content')
  df_temp2 = df_temp2.to_frame(name='Label')
  df_3_2 = df_temp1.join(df_temp2)
  table = [df_3_2,df_huang]
  pd.concat(table)

  df_huang = df_huang.append(df_3_1)
  df_huang = df_huang.append(df_3_2)
  print(df_huang.size)
  df_huang.to_csv("data_huang.csv")