{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"CharacterEmbedding.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1_O9fePBZLmEhZxLnLmmxtPToIeKa5v2y","authorship_tag":"ABX9TyPXCVrpcJ6ym3eV3JJ70DED"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"SU8g-zS0g7vF"},"source":["import numpy as np\n","import string, time \n","import pandas as pd \n","from keras.models import Model\n","from keras.layers import Dense, Input, Embedding\n","from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPool1D, Dropout, concatenate\n","from keras.preprocessing import text as keras_text, sequence as keras_seq\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DBbW9HPoCR7A"},"source":["#decorator function for calculating the total time reqired to execute various function\n","def calc_time(func):\n","  def inner(*args, **kwargs):\n","    st = time.time()\n","    result = func(*args,**kwargs)\n","    end = time.time()-st\n","    print(\"Total time required: {:.3f} ms\".format(end * 1000))\n","    return result\n","  return inner"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xZ32O2vmhIUw"},"source":["#function is used to tokenize, create character embedding vocabulary and save the best model during the training of the model\n","def train_model(train,test):\n","\n","  #hyper parameters\n","  max_features = 64\n","  maxlen = 512\n","\n","  list_sentences_train = train[\"Content\"].fillna(\"unknown\").values\n","  list_classes = [\"Label\"]\n","  y = train[list_classes].values\n","  list_sentences_test = test[\"Content\"].fillna(\"unknown\").values\n","\n","  #sequence generation\n","  tokenizer = keras_text.Tokenizer(num_words=None, char_level=True, oov_token='UNK')\n","  tokenizer.fit_on_texts(list(string.printable))\n","\n","  print(\"length of word_index\",len(tokenizer.word_index))\n","  print(\"length of word_counts\",len(tokenizer.word_counts))\n","  print(\"length of index_word\",len(tokenizer.index_word))\n","  #print(tokenizer.word_index)\n","  #train data\n","  list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n","  X_t = keras_seq.pad_sequences(list_tokenized_train, maxlen=maxlen)\n","  \n","  #test data  \n","  list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)\n","  X_te = keras_seq.pad_sequences(list_tokenized_test, maxlen=maxlen)\n","\n","  any_category_positive = np.sum(y,1)\n","  print('Distribution of Total Positive Labels (important for validation)')\n","  print(pd.value_counts(any_category_positive))\n","  X_t_train, X_t_test, y_train, y_test = train_test_split(X_t, y, \n","                                                          test_size = 0.2, \n","                                                          stratify = any_category_positive,\n","                                                          random_state = 2017)\n","\n","  print('Training:', X_t_train.shape)\n","  print('Testing:', X_t_test.shape)\n","\n","  batch_size = 128 # large enough that some other labels come in\n","  epochs = len(X_te)\n","\n","  #file path to save the best character embedding weights\n","  file_path=\"/content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/EmbeddingFileVocabData/char_embedding_weights.h5\"\n","\n","  #checkpoint at every epoh and save the best model\n","  checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n","\n","  #stop training of the model if there is no further improvement\n","  early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n","\n","  callbacks_list = [checkpoint, early]\n","\n","  #character embedding model\n","  def build_model(conv_layers = 2, \n","                dilation_rates = [0, 2, 4, 8, 16], \n","                embed_size = 300):\n","    inp = Input(shape=(None, ))\n","    x = Embedding(input_dim = len(tokenizer.word_index)+1, \n","                  output_dim = embed_size)(inp)\n","    prefilt_x = Dropout(0.25)(x)\n","    out_conv = []\n","    # dilation rate lets us use ngrams and skip grams to process \n","    for dilation_rate in dilation_rates:\n","        x = prefilt_x\n","        for i in range(2):\n","            if dilation_rate>0:\n","                x = Conv1D(16*2**(i), \n","                           kernel_size = 3, \n","                           dilation_rate = dilation_rate,\n","                          activation = 'relu',\n","                          name = 'ngram_{}_cnn_{}'.format(dilation_rate, i)\n","                          )(x)\n","            else:\n","                x = Conv1D(16*2**(i), \n","                           kernel_size = 1,\n","                          activation = 'relu',\n","                          name = 'word_fcl_{}'.format(i))(x)\n","        out_conv += [Dropout(0.5)(GlobalMaxPool1D()(x))]\n","    x = concatenate(out_conv, axis = -1)    \n","    x = Dense(64, activation='relu')(x)\n","    x = Dropout(0.1)(x)\n","    x = Dense(32, activation='relu')(x)\n","    x = Dropout(0.1)(x)\n","    x = Dense(1, activation='sigmoid')(x)\n","    model = Model(inputs=inp, outputs=x)\n","    model.compile(loss='binary_crossentropy',\n","                  optimizer='adam',\n","                  metrics=['accuracy'])\n","    return model\n","\n","  #build the model\n","  model = build_model()\n","\n","  #display model summary\n","  model.summary()\n","\n","  model.fit(X_t_train, y_train, \n","          validation_data=(X_t_test, y_test),\n","          batch_size=batch_size, \n","          epochs=epochs, \n","          shuffle = True,\n","          callbacks=callbacks_list)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ePNtRH81hUsF"},"source":["@calc_time\n","def main():\n","  \n","  #get the final cleaned data\n","  df=pd.read_csv('/content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/EmbeddingFileVocabData/final_preprocessed_data_yidong_devansh_clean.csv',names=[\"Content\",\"Label\"])\n","\n","  #split dataset into train and test\n","  train, test = train_test_split(df, test_size=0.3, random_state=1, shuffle=True)\n","\n","  #shuffle dataset\n","  train = train.sample(frac=1)\n","\n","  #reset index for train and test\n","  train.reset_index(drop=True, inplace=True)\n","  test.reset_index(drop=True, inplace=True)\n","\n","  #this is used to find the maximum length of sentence in our data\n","  df[\"maxlen\"] = df.Content.apply(lambda x: len(x.split()))\n","  print(\"Maximum length of words in a sentence\",max(df[\"maxlen\"].values))\n","\n","  train_model(train,test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-cDXpnx8Fkor","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637698592425,"user_tz":300,"elapsed":11287549,"user":{"displayName":"Devansh Sundeep Mody","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13806827833421197310"}},"outputId":"770004b2-eabe-4c13-91f1-a8bc9919eba9"},"source":["if __name__:main()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Maximum length of words in a sentence 3750\n","length of word_index 75\n","length of word_counts 74\n","length of index_word 75\n","Distribution of Total Positive Labels (important for validation)\n","0    283728\n","1     55891\n","dtype: int64\n","Training: (271695, 512)\n","Testing: (67924, 512)\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," input_2 (InputLayer)           [(None, None)]       0           []                               \n","                                                                                                  \n"," embedding_1 (Embedding)        (None, None, 300)    22800       ['input_2[0][0]']                \n","                                                                                                  \n"," dropout_8 (Dropout)            (None, None, 300)    0           ['embedding_1[0][0]']            \n","                                                                                                  \n"," word_fcl_0 (Conv1D)            (None, None, 16)     4816        ['dropout_8[0][0]']              \n","                                                                                                  \n"," ngram_2_cnn_0 (Conv1D)         (None, None, 16)     14416       ['dropout_8[0][0]']              \n","                                                                                                  \n"," ngram_4_cnn_0 (Conv1D)         (None, None, 16)     14416       ['dropout_8[0][0]']              \n","                                                                                                  \n"," ngram_8_cnn_0 (Conv1D)         (None, None, 16)     14416       ['dropout_8[0][0]']              \n","                                                                                                  \n"," ngram_16_cnn_0 (Conv1D)        (None, None, 16)     14416       ['dropout_8[0][0]']              \n","                                                                                                  \n"," word_fcl_1 (Conv1D)            (None, None, 32)     544         ['word_fcl_0[0][0]']             \n","                                                                                                  \n"," ngram_2_cnn_1 (Conv1D)         (None, None, 32)     1568        ['ngram_2_cnn_0[0][0]']          \n","                                                                                                  \n"," ngram_4_cnn_1 (Conv1D)         (None, None, 32)     1568        ['ngram_4_cnn_0[0][0]']          \n","                                                                                                  \n"," ngram_8_cnn_1 (Conv1D)         (None, None, 32)     1568        ['ngram_8_cnn_0[0][0]']          \n","                                                                                                  \n"," ngram_16_cnn_1 (Conv1D)        (None, None, 32)     1568        ['ngram_16_cnn_0[0][0]']         \n","                                                                                                  \n"," global_max_pooling1d_5 (Global  (None, 32)          0           ['word_fcl_1[0][0]']             \n"," MaxPooling1D)                                                                                    \n","                                                                                                  \n"," global_max_pooling1d_6 (Global  (None, 32)          0           ['ngram_2_cnn_1[0][0]']          \n"," MaxPooling1D)                                                                                    \n","                                                                                                  \n"," global_max_pooling1d_7 (Global  (None, 32)          0           ['ngram_4_cnn_1[0][0]']          \n"," MaxPooling1D)                                                                                    \n","                                                                                                  \n"," global_max_pooling1d_8 (Global  (None, 32)          0           ['ngram_8_cnn_1[0][0]']          \n"," MaxPooling1D)                                                                                    \n","                                                                                                  \n"," global_max_pooling1d_9 (Global  (None, 32)          0           ['ngram_16_cnn_1[0][0]']         \n"," MaxPooling1D)                                                                                    \n","                                                                                                  \n"," dropout_9 (Dropout)            (None, 32)           0           ['global_max_pooling1d_5[0][0]'] \n","                                                                                                  \n"," dropout_10 (Dropout)           (None, 32)           0           ['global_max_pooling1d_6[0][0]'] \n","                                                                                                  \n"," dropout_11 (Dropout)           (None, 32)           0           ['global_max_pooling1d_7[0][0]'] \n","                                                                                                  \n"," dropout_12 (Dropout)           (None, 32)           0           ['global_max_pooling1d_8[0][0]'] \n","                                                                                                  \n"," dropout_13 (Dropout)           (None, 32)           0           ['global_max_pooling1d_9[0][0]'] \n","                                                                                                  \n"," concatenate_1 (Concatenate)    (None, 160)          0           ['dropout_9[0][0]',              \n","                                                                  'dropout_10[0][0]',             \n","                                                                  'dropout_11[0][0]',             \n","                                                                  'dropout_12[0][0]',             \n","                                                                  'dropout_13[0][0]']             \n","                                                                                                  \n"," dense_3 (Dense)                (None, 64)           10304       ['concatenate_1[0][0]']          \n","                                                                                                  \n"," dropout_14 (Dropout)           (None, 64)           0           ['dense_3[0][0]']                \n","                                                                                                  \n"," dense_4 (Dense)                (None, 32)           2080        ['dropout_14[0][0]']             \n","                                                                                                  \n"," dropout_15 (Dropout)           (None, 32)           0           ['dense_4[0][0]']                \n","                                                                                                  \n"," dense_5 (Dense)                (None, 1)            33          ['dropout_15[0][0]']             \n","                                                                                                  \n","==================================================================================================\n","Total params: 104,513\n","Trainable params: 104,513\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n","Epoch 1/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.4054 - accuracy: 0.8364\n","Epoch 00001: val_loss improved from inf to 0.37833, saving model to /content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/EmbeddingFileVocabData/char_embedding_weights.h5\n","2123/2123 [==============================] - 320s 145ms/step - loss: 0.4054 - accuracy: 0.8364 - val_loss: 0.3783 - val_accuracy: 0.8399\n","Epoch 2/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.3789 - accuracy: 0.8414\n","Epoch 00002: val_loss improved from 0.37833 to 0.36052, saving model to /content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/EmbeddingFileVocabData/char_embedding_weights.h5\n","2123/2123 [==============================] - 307s 145ms/step - loss: 0.3789 - accuracy: 0.8414 - val_loss: 0.3605 - val_accuracy: 0.8442\n","Epoch 3/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.3713 - accuracy: 0.8447\n","Epoch 00003: val_loss improved from 0.36052 to 0.35513, saving model to /content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/EmbeddingFileVocabData/char_embedding_weights.h5\n","2123/2123 [==============================] - 307s 145ms/step - loss: 0.3713 - accuracy: 0.8447 - val_loss: 0.3551 - val_accuracy: 0.8467\n","Epoch 4/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.3652 - accuracy: 0.8465\n","Epoch 00004: val_loss improved from 0.35513 to 0.35034, saving model to /content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/EmbeddingFileVocabData/char_embedding_weights.h5\n","2123/2123 [==============================] - 307s 145ms/step - loss: 0.3652 - accuracy: 0.8465 - val_loss: 0.3503 - val_accuracy: 0.8471\n","Epoch 5/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.3624 - accuracy: 0.8472\n","Epoch 00005: val_loss improved from 0.35034 to 0.34704, saving model to /content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/EmbeddingFileVocabData/char_embedding_weights.h5\n","2123/2123 [==============================] - 307s 145ms/step - loss: 0.3624 - accuracy: 0.8472 - val_loss: 0.3470 - val_accuracy: 0.8479\n","Epoch 6/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.3587 - accuracy: 0.8485\n","Epoch 00006: val_loss improved from 0.34704 to 0.33977, saving model to /content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/EmbeddingFileVocabData/char_embedding_weights.h5\n","2123/2123 [==============================] - 326s 154ms/step - loss: 0.3587 - accuracy: 0.8485 - val_loss: 0.3398 - val_accuracy: 0.8531\n","Epoch 7/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.3571 - accuracy: 0.8493\n","Epoch 00007: val_loss did not improve from 0.33977\n","2123/2123 [==============================] - 307s 144ms/step - loss: 0.3571 - accuracy: 0.8493 - val_loss: 0.3439 - val_accuracy: 0.8502\n","Epoch 8/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.3551 - accuracy: 0.8495\n","Epoch 00008: val_loss did not improve from 0.33977\n","2123/2123 [==============================] - 309s 145ms/step - loss: 0.3551 - accuracy: 0.8495 - val_loss: 0.3453 - val_accuracy: 0.8538\n","Epoch 9/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.3542 - accuracy: 0.8502\n","Epoch 00009: val_loss improved from 0.33977 to 0.33885, saving model to /content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/EmbeddingFileVocabData/char_embedding_weights.h5\n","2123/2123 [==============================] - 309s 146ms/step - loss: 0.3542 - accuracy: 0.8502 - val_loss: 0.3389 - val_accuracy: 0.8486\n","Epoch 10/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.3529 - accuracy: 0.8504\n","Epoch 00010: val_loss did not improve from 0.33885\n","2123/2123 [==============================] - 327s 154ms/step - loss: 0.3529 - accuracy: 0.8504 - val_loss: 0.3401 - val_accuracy: 0.8493\n","Epoch 11/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.3514 - accuracy: 0.8508\n","Epoch 00011: val_loss improved from 0.33885 to 0.33862, saving model to /content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/EmbeddingFileVocabData/char_embedding_weights.h5\n","2123/2123 [==============================] - 309s 146ms/step - loss: 0.3514 - accuracy: 0.8508 - val_loss: 0.3386 - val_accuracy: 0.8546\n","Epoch 12/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.3501 - accuracy: 0.8507\n","Epoch 00012: val_loss did not improve from 0.33862\n","2123/2123 [==============================] - 309s 145ms/step - loss: 0.3501 - accuracy: 0.8507 - val_loss: 0.3450 - val_accuracy: 0.8514\n","Epoch 13/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.3493 - accuracy: 0.8516\n","Epoch 00013: val_loss improved from 0.33862 to 0.33821, saving model to /content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/EmbeddingFileVocabData/char_embedding_weights.h5\n","2123/2123 [==============================] - 309s 145ms/step - loss: 0.3493 - accuracy: 0.8516 - val_loss: 0.3382 - val_accuracy: 0.8498\n","Epoch 14/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.3481 - accuracy: 0.8519\n","Epoch 00014: val_loss did not improve from 0.33821\n","2123/2123 [==============================] - 308s 145ms/step - loss: 0.3481 - accuracy: 0.8519 - val_loss: 0.3391 - val_accuracy: 0.8472\n","Epoch 15/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.3474 - accuracy: 0.8525\n","Epoch 00015: val_loss improved from 0.33821 to 0.33661, saving model to /content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/EmbeddingFileVocabData/char_embedding_weights.h5\n","2123/2123 [==============================] - 309s 145ms/step - loss: 0.3474 - accuracy: 0.8525 - val_loss: 0.3366 - val_accuracy: 0.8529\n","Epoch 16/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.3477 - accuracy: 0.8522\n","Epoch 00016: val_loss improved from 0.33661 to 0.33465, saving model to /content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/EmbeddingFileVocabData/char_embedding_weights.h5\n","2123/2123 [==============================] - 309s 145ms/step - loss: 0.3477 - accuracy: 0.8522 - val_loss: 0.3347 - val_accuracy: 0.8505\n","Epoch 17/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.3458 - accuracy: 0.8521\n","Epoch 00017: val_loss did not improve from 0.33465\n","2123/2123 [==============================] - 309s 145ms/step - loss: 0.3458 - accuracy: 0.8521 - val_loss: 0.3350 - val_accuracy: 0.8511\n","Epoch 18/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.3457 - accuracy: 0.8527\n","Epoch 00018: val_loss did not improve from 0.33465\n","2123/2123 [==============================] - 309s 146ms/step - loss: 0.3457 - accuracy: 0.8527 - val_loss: 0.3356 - val_accuracy: 0.8489\n","Epoch 19/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.3444 - accuracy: 0.8538\n","Epoch 00019: val_loss did not improve from 0.33465\n","2123/2123 [==============================] - 328s 154ms/step - loss: 0.3444 - accuracy: 0.8538 - val_loss: 0.3348 - val_accuracy: 0.8502\n","Epoch 20/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.3442 - accuracy: 0.8536\n","Epoch 00020: val_loss improved from 0.33465 to 0.33364, saving model to /content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/EmbeddingFileVocabData/char_embedding_weights.h5\n","2123/2123 [==============================] - 310s 146ms/step - loss: 0.3442 - accuracy: 0.8536 - val_loss: 0.3336 - val_accuracy: 0.8530\n","Epoch 21/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.3437 - accuracy: 0.8533\n","Epoch 00021: val_loss did not improve from 0.33364\n","2123/2123 [==============================] - 309s 145ms/step - loss: 0.3437 - accuracy: 0.8533 - val_loss: 0.3382 - val_accuracy: 0.8515\n","Epoch 22/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.3430 - accuracy: 0.8536\n","Epoch 00022: val_loss improved from 0.33364 to 0.33352, saving model to /content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/EmbeddingFileVocabData/char_embedding_weights.h5\n","2123/2123 [==============================] - 309s 145ms/step - loss: 0.3430 - accuracy: 0.8536 - val_loss: 0.3335 - val_accuracy: 0.8555\n","Epoch 23/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.3427 - accuracy: 0.8540\n","Epoch 00023: val_loss did not improve from 0.33352\n","2123/2123 [==============================] - 308s 145ms/step - loss: 0.3427 - accuracy: 0.8540 - val_loss: 0.3360 - val_accuracy: 0.8500\n","Epoch 24/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.3419 - accuracy: 0.8541\n","Epoch 00024: val_loss did not improve from 0.33352\n","2123/2123 [==============================] - 308s 145ms/step - loss: 0.3419 - accuracy: 0.8541 - val_loss: 0.3354 - val_accuracy: 0.8530\n","Epoch 25/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.3422 - accuracy: 0.8538\n","Epoch 00025: val_loss did not improve from 0.33352\n","2123/2123 [==============================] - 309s 145ms/step - loss: 0.3422 - accuracy: 0.8538 - val_loss: 0.3347 - val_accuracy: 0.8543\n","Epoch 26/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.3413 - accuracy: 0.8540\n","Epoch 00026: val_loss improved from 0.33352 to 0.33264, saving model to /content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/EmbeddingFileVocabData/char_embedding_weights.h5\n","2123/2123 [==============================] - 311s 146ms/step - loss: 0.3413 - accuracy: 0.8540 - val_loss: 0.3326 - val_accuracy: 0.8549\n","Epoch 27/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.3404 - accuracy: 0.8544\n","Epoch 00027: val_loss improved from 0.33264 to 0.32932, saving model to /content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/EmbeddingFileVocabData/char_embedding_weights.h5\n","2123/2123 [==============================] - 330s 156ms/step - loss: 0.3404 - accuracy: 0.8544 - val_loss: 0.3293 - val_accuracy: 0.8568\n","Epoch 28/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.3408 - accuracy: 0.8548\n","Epoch 00028: val_loss did not improve from 0.32932\n","2123/2123 [==============================] - 310s 146ms/step - loss: 0.3408 - accuracy: 0.8548 - val_loss: 0.3322 - val_accuracy: 0.8536\n","Epoch 29/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.3401 - accuracy: 0.8543\n","Epoch 00029: val_loss did not improve from 0.32932\n","2123/2123 [==============================] - 330s 155ms/step - loss: 0.3401 - accuracy: 0.8543 - val_loss: 0.3334 - val_accuracy: 0.8488\n","Epoch 30/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.3386 - accuracy: 0.8549\n","Epoch 00030: val_loss did not improve from 0.32932\n","2123/2123 [==============================] - 310s 146ms/step - loss: 0.3386 - accuracy: 0.8549 - val_loss: 0.3371 - val_accuracy: 0.8483\n","Epoch 31/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.3394 - accuracy: 0.8553\n","Epoch 00031: val_loss improved from 0.32932 to 0.32857, saving model to /content/drive/MyDrive/COMP-5800-YDE-Yidong-Devansh-Final-Project/EmbeddingFileVocabData/char_embedding_weights.h5\n","2123/2123 [==============================] - 311s 146ms/step - loss: 0.3394 - accuracy: 0.8553 - val_loss: 0.3286 - val_accuracy: 0.8558\n","Epoch 32/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.3382 - accuracy: 0.8554\n","Epoch 00032: val_loss did not improve from 0.32857\n","2123/2123 [==============================] - 311s 146ms/step - loss: 0.3382 - accuracy: 0.8554 - val_loss: 0.3351 - val_accuracy: 0.8477\n","Epoch 33/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.3383 - accuracy: 0.8549\n","Epoch 00033: val_loss did not improve from 0.32857\n","2123/2123 [==============================] - 311s 146ms/step - loss: 0.3383 - accuracy: 0.8549 - val_loss: 0.3315 - val_accuracy: 0.8521\n","Epoch 34/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.3378 - accuracy: 0.8556\n","Epoch 00034: val_loss did not improve from 0.32857\n","2123/2123 [==============================] - 311s 146ms/step - loss: 0.3378 - accuracy: 0.8556 - val_loss: 0.3306 - val_accuracy: 0.8530\n","Epoch 35/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.3371 - accuracy: 0.8562\n","Epoch 00035: val_loss did not improve from 0.32857\n","2123/2123 [==============================] - 312s 147ms/step - loss: 0.3371 - accuracy: 0.8562 - val_loss: 0.3317 - val_accuracy: 0.8535\n","Epoch 36/145551\n","2123/2123 [==============================] - ETA: 0s - loss: 0.3365 - accuracy: 0.8559\n","Epoch 00036: val_loss did not improve from 0.32857\n","2123/2123 [==============================] - 312s 147ms/step - loss: 0.3365 - accuracy: 0.8559 - val_loss: 0.3317 - val_accuracy: 0.8526\n","Total time required: 11287632.127 ms\n"]}]},{"cell_type":"code","metadata":{"id":"u81G1St4AAFz"},"source":[""],"execution_count":null,"outputs":[]}]}