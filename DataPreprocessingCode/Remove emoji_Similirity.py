# -*- coding: utf-8 -*-
"""Project_Dvensh_YiDong.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1P-J5nJoxjAo88sCv1-teBQtZ9xEcKRTY
"""

pip install chart-studio

import numpy as np 
import pandas as pd

from google.colab import drive
drive.mount('/content/drive')

import re

### This part is for removing emoji
def filter_emoji(desstr, restr=''):
    try:
        co = re.compile(u'[\U00010000-\U0010ffff]')
    except re.error:
        co = re.compile(u'[\uD800-\uDBFF][\uDC00-\uDFFF]')
    return co.sub(restr, desstr)

#similirity step 1: token the scentence to words
#      step 2: convert a word to vector
#      step 3: compare each words in scentence with all words in english.csv, caculate the similirty, if the 
# similrity value over 0.6 mark the Label as 1(hate speech) 

import nltk
from nltk.tokenize import word_tokenize
nltk.download('punkt')
import numpy as np 
import pandas as pd

def word2vec(word):
    from collections import Counter
    from math import sqrt

    # count the characters in word
    cw = Counter(word)
    # precomputes a set of the different characters
    sw = set(cw)
    # precomputes the "length" of the word vector
    lw = sqrt(sum(c*c for c in cw.values()))

    # return a tuple
    return cw, sw, lw

def cosdis(v1, v2):
    # which characters are common to the two words?
    try:
      common = v1[1].intersection(v2[1])
    # by definition of cosine distance we have
      return sum(v1[0][ch]*v2[0][ch] for ch in common)/v1[2]/v2[2]
    except IndexError:
      return 0


# Edit Distance Similirty
def edit_distance(str1, str2):
    m, n = len(str1), len(str2)
    if m==0 and n!=0:
        return n, 1-n/max(m, n)
    elif m!=0 and n==0:
        return m, 1-m/max(m, n)
    elif m==0 and n==0:
        try:
            1-0/0
        except ZeroDivisionError as z:
            print("string can not be null")
        return math.nan, math.nan
    else:
        d = np.zeros((n+1, m+1))
        d[0] = np.arange(m+1)
        d[:, 0] = np.arange(n+1)
        for i in range(1, n+1):
            for j in range(1, m+1):
                if str1[j-1]==str2[i-1]:
                    temp = 0
                else:
                    temp = 1
                d[i, j] = min(d[i-1, j]+1, d[i, j-1]+1, d[i-1, j-1]+temp)
        return d[n, m], 1-d[n, m]/max(m, n)

 
 


# Program to measure the similarity between
# two sentences using cosine similarity.

def ForDataSet(data_path = '/content/drive/MyDrive/HateSpeechDataSet/data_huang_devansh.csv',english_path='/content/drive/MyDrive/HateSpeechDataSet/english.csv'):
  data = pd.read_csv(data_path)
  words_list = []
  words = pd.read_csv(english_path)
  for i in range(0,376):
    words_list.append(words.iloc[i][0])

  for i in range(1,842333):
    scentenct = data.iloc[i]['Content']
    scentenct = filter_emoji(scentenct)
    data.iloc[i]['Content'] = scentenct
    all_words = word_tokenize(scentenct)
    for word1 in all_words:
      for word2 in words_list:
        w1 = word2vec(word1)
        w2 = word2vec(word2)
        if cosdis(w1,w2) > 0.6:
          scentenct.replace(word1,word2)
          data.iloc[i]['Content'] = scentenct
        if edit_distance(word1,word2)[1] > 0.5:
          scentenct.replace(word1,word2)
          data.iloc[i]['Content'] = scentenct

ForDataSet()